{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f759dd",
   "metadata": {},
   "source": [
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee3d10",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "With the widespread use of credit cards, fraud has emerged as a major issue in the credit card business in the banking world. Misuse of this credit card is known to result in considerable losses. So referring to the [Journal Article](https://ieeexplore.ieee.org/abstract/document/9000549), credit card fraud detection is an important study in the current era of mobile payments. The existence of a fraud pattern that is changing rapidly needs to be evaluated so that the approach can be more proactive to prevent fraud. In this case, the application of an efficient fraud detection algorithm using machine learning techniques is a reliable alternative to help detect fraud so as to reduce the resulting losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa06109",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Overall, this project offers the objectives and contributions as follows:\n",
    "\n",
    "   1. Build machine learning model to classify and predict the status of credit card transaction, whether fraud or not. \n",
    "   2. Deploy the model performance to new datasets in web applications. Providing the probability of the transaction to being fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a00378",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad655f4d",
   "metadata": {},
   "source": [
    "This is a simulated credit card transaction dataset containing both legitimate and fraudulent transactions during 1 Jan 2019 - 31 Dec 2020. It includes credit cards of 1000 customers who transacted with 800 merchants.\n",
    "\n",
    "Source : https://github.com/namebrandon/Sparkov_Data_Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c2836a",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d3a893",
   "metadata": {},
   "source": [
    "The data used is `fraudTrain.csv` as dataset to create machine learning model (**training**) and `fraud_test.csv` as dataset to evaluate the model (**testing**). The following code is reading the data using pandas then creating a preview for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ff417de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T23:56:46.839779Z",
     "start_time": "2022-02-16T23:56:46.834790Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfff2f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T23:56:49.385295Z",
     "start_time": "2022-02-16T23:56:49.204777Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "0           0   2019-01-01 00:00:18  2703186189652095   \n",
       "1           1   2019-01-01 00:00:44      630423337322   \n",
       "2           2   2019-01-01 00:00:51    38859492057661   \n",
       "3           3   2019-01-01 00:01:16  3534093764340240   \n",
       "4           4   2019-01-01 00:03:06   375534208663984   \n",
       "\n",
       "                             merchant       category     amt      first  \\\n",
       "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
       "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
       "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
       "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
       "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
       "\n",
       "      last gender                        street  ...      lat      long  \\\n",
       "0    Banks      F                561 Perry Cove  ...  36.0788  -81.1781   \n",
       "1     Gill      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105   \n",
       "2  Sanchez      M      594 White Dale Suite 530  ...  42.1808 -112.2620   \n",
       "3    White      M   9443 Cynthia Court Apt. 038  ...  46.2306 -112.1138   \n",
       "4   Garcia      M              408 Bradley Rest  ...  38.4207  -79.4629   \n",
       "\n",
       "   city_pop                                job         dob  \\\n",
       "0      3495          Psychologist, counselling  1988-03-09   \n",
       "1       149  Special educational needs teacher  1978-06-21   \n",
       "2      4154        Nature conservation officer  1962-01-19   \n",
       "3      1939                    Patent attorney  1967-01-12   \n",
       "4        99     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_train = pd.read_csv(\"fraudTrain.csv\")\n",
    "fraud_test = pd.read_csv(\"fraud_test.csv\")\n",
    "fraud_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbba318",
   "metadata": {},
   "source": [
    "Description of the Dataset:\n",
    "\n",
    "- `trans_date_trans_time` : transaction time (yyyy/mm/dd hh:mm:ss)\n",
    "- `cc_num` : credit card number\n",
    "- `merchant` : name of merchant\n",
    "- `category` : category of the merchant\n",
    "- `amt` : transaction amount\n",
    "- `first` : first name of credit card holder\n",
    "- `last` : last name of credit card holder\n",
    "- `gender` : F= female, M = male\n",
    "- `street` : street address of the credit card holder\n",
    "- `city` : city address of the credit card holder\n",
    "- `state` : state address of the credit card holder\n",
    "- `zip` : zip code address of the credit card holder\n",
    "- `lat` : latitude location of the credit card holder\n",
    "- `long` : longitude location of the credit card holder\n",
    "- `city_pop` : number of city population\n",
    "- `job` : job of credit card holder\n",
    "- `dob` : date of birth of credit card holder\n",
    "- `trans_num` : transaction number\n",
    "- `unix_time` : system for describing a point in time\n",
    "- `merch_lat` : latitude location of the merchant\n",
    "- `merch_long` : merchant longitude\n",
    "- `is_fraud` : 0 = Not Fraud, 1 = Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42bcfdc",
   "metadata": {},
   "source": [
    "Then, further inspection for dataset `fraud_train` and `fraud_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2f8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1296675 non-null  int64  \n",
      " 1   trans_date_trans_time  1296675 non-null  object \n",
      " 2   cc_num                 1296675 non-null  int64  \n",
      " 3   merchant               1296675 non-null  object \n",
      " 4   category               1296675 non-null  object \n",
      " 5   amt                    1296675 non-null  float64\n",
      " 6   first                  1296675 non-null  object \n",
      " 7   last                   1296675 non-null  object \n",
      " 8   gender                 1296675 non-null  object \n",
      " 9   street                 1296675 non-null  object \n",
      " 10  city                   1296675 non-null  object \n",
      " 11  state                  1296675 non-null  object \n",
      " 12  zip                    1296675 non-null  int64  \n",
      " 13  lat                    1296675 non-null  float64\n",
      " 14  long                   1296675 non-null  float64\n",
      " 15  city_pop               1296675 non-null  int64  \n",
      " 16  job                    1296675 non-null  object \n",
      " 17  dob                    1296675 non-null  object \n",
      " 18  trans_num              1296675 non-null  object \n",
      " 19  unix_time              1296675 non-null  int64  \n",
      " 20  merch_lat              1296675 non-null  float64\n",
      " 21  merch_long             1296675 non-null  float64\n",
      " 22  is_fraud               1296675 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 227.5+ MB\n"
     ]
    }
   ],
   "source": [
    "fraud_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4118dca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T23:57:05.899491Z",
     "start_time": "2022-02-16T23:57:05.881539Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4290 entries, 0 to 4289\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             4290 non-null   int64  \n",
      " 1   trans_date_trans_time  4290 non-null   object \n",
      " 2   cc_num                 4290 non-null   int64  \n",
      " 3   merchant               4290 non-null   object \n",
      " 4   category               4290 non-null   object \n",
      " 5   amt                    4290 non-null   float64\n",
      " 6   first                  4290 non-null   object \n",
      " 7   last                   4290 non-null   object \n",
      " 8   gender                 4290 non-null   object \n",
      " 9   street                 4290 non-null   object \n",
      " 10  city                   4290 non-null   object \n",
      " 11  state                  4290 non-null   object \n",
      " 12  zip                    4290 non-null   int64  \n",
      " 13  lat                    4290 non-null   float64\n",
      " 14  long                   4290 non-null   float64\n",
      " 15  city_pop               4290 non-null   int64  \n",
      " 16  job                    4290 non-null   object \n",
      " 17  dob                    4290 non-null   object \n",
      " 18  trans_num              4290 non-null   object \n",
      " 19  unix_time              4290 non-null   int64  \n",
      " 20  merch_lat              4290 non-null   float64\n",
      " 21  merch_long             4290 non-null   float64\n",
      " 22  is_fraud               4290 non-null   int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 771.0+ KB\n"
     ]
    }
   ],
   "source": [
    "fraud_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7078dcb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4290, 23)\n",
      "(1296675, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fraud_test.shape),print(fraud_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d06f24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88a477e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43352eab",
   "metadata": {},
   "source": [
    "Based on the above inspection, we got some information:\n",
    "- There are some columns that do not have the appropriate data type\n",
    "- Since 1 row represents one transaction, in the train dataset there are 1,296,675 transactions that will be used for model learning, and there are 4290 transactions to predict\n",
    "- No missing values in both data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885f6b63",
   "metadata": {},
   "source": [
    "## Data Cleaning & Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babcb89",
   "metadata": {},
   "source": [
    "The first step in data preparation is removing meaningless column `Unnamed: 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef4d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_train.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "fraud_test.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d50f2d",
   "metadata": {},
   "source": [
    "Then, change the value of column `is_fraud` to make it more informative.\n",
    "- With a value of 0 then it is changed to **No**, which means **No Fraud**\n",
    "- With a value of 1, it is changed to **Yes**, which means **Fraud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f0ecb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Yes\n",
       "1        No\n",
       "2       Yes\n",
       "3        No\n",
       "4       Yes\n",
       "       ... \n",
       "4285     No\n",
       "4286    Yes\n",
       "4287     No\n",
       "4288     No\n",
       "4289     No\n",
       "Name: is_fraud, Length: 4290, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_train[\"is_fraud\"]=fraud_train.is_fraud.apply(lambda x: \"Yes\" if x==1 else \"No\")\n",
    "fraud_test[\"is_fraud\"]=fraud_test.is_fraud.apply(lambda x: \"Yes\" if x==1 else \"No\")\n",
    "\n",
    "fraud_train[\"is_fraud\"].astype(\"object\")\n",
    "fraud_test[\"is_fraud\"].astype(\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c9952",
   "metadata": {},
   "source": [
    "The next step is adjusting the datetime data types, namely `trans_date_trans_time` and `dob`. This is done to extract the date information stored in a new columns `trans_date` and `age`. These changes are made to both the train data and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f469a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trans_date and age columns on dataset train\n",
    "fraud_train['trans_date_trans_time']=pd.to_datetime(fraud_train['trans_date_trans_time'])\n",
    "fraud_train['trans_date']=fraud_train['trans_date_trans_time'].dt.strftime('%Y-%m-%d')\n",
    "fraud_train['trans_date']=pd.to_datetime(fraud_train['trans_date'])\n",
    "\n",
    "fraud_train['dob']=pd.to_datetime(fraud_train['dob'])\n",
    "fraud_train[\"age\"] = fraud_train[\"trans_date\"]- fraud_train[\"dob\"]\n",
    "fraud_train[\"age\"]= fraud_train[\"age\"].astype('timedelta64[Y]')\n",
    "\n",
    "# create trans_date and age columns on dataset test\n",
    "fraud_test['trans_date_trans_time']=pd.to_datetime(fraud_test['trans_date_trans_time'])\n",
    "fraud_test['trans_date']=fraud_test['trans_date_trans_time'].dt.strftime('%Y-%m-%d')\n",
    "fraud_test['trans_date']=pd.to_datetime(fraud_test['trans_date'])\n",
    "\n",
    "fraud_test['dob']=pd.to_datetime(fraud_test['dob'])\n",
    "fraud_test[\"age\"] = fraud_test[\"trans_date\"]- fraud_test[\"dob\"]\n",
    "fraud_test[\"age\"]= fraud_test[\"age\"].astype('timedelta64[Y]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea363180",
   "metadata": {},
   "source": [
    "For getting month and year information of the transaction, we will extract from `trans_date`. The month and year information consider more informative to classify the status of the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ffd72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_train['trans_month'] = fraud_train['trans_date'].dt.month\n",
    "fraud_train['trans_year'] = fraud_train['trans_date'].dt.year\n",
    "\n",
    "fraud_test['trans_month'] = fraud_test['trans_date'].dt.month\n",
    "fraud_test['trans_year'] = fraud_test['trans_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878da41c",
   "metadata": {},
   "source": [
    "Next is find out the distance from the card holder location to merchant location in degrees latitude and degrees longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29fddb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_train['latitudinal_distance'] = abs(round(fraud_train['merch_lat']-fraud_train['lat'],3))\n",
    "fraud_train['longitudinal_distance'] = abs(round(fraud_train['merch_long']-fraud_train['long'],3))\n",
    "\n",
    "fraud_test['latitudinal_distance'] = abs(round(fraud_test['merch_lat']-fraud_test['lat'],3))\n",
    "fraud_test['longitudinal_distance'] = abs(round(fraud_test['merch_long']-fraud_test['long'],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13d78e",
   "metadata": {},
   "source": [
    "There are a few columns that have extracted valuable information and columns that are not needed for modeling, so they can be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a475ffa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_cols = ['cc_num','trans_date_trans_time','trans_num','city','lat','long','job','dob','merch_lat','merch_long','trans_date','state', 'merchant','first','last','street','zip','unix_time']\n",
    "fraud_train=fraud_train.drop(drop_cols,axis=1)\n",
    "fraud_test=fraud_test.drop(drop_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "528e4d55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4290 entries, 0 to 4289\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   category               4290 non-null   object \n",
      " 1   amt                    4290 non-null   float64\n",
      " 2   gender                 4290 non-null   object \n",
      " 3   city_pop               4290 non-null   int64  \n",
      " 4   is_fraud               4290 non-null   object \n",
      " 5   age                    4290 non-null   float64\n",
      " 6   trans_month            4290 non-null   int64  \n",
      " 7   trans_year             4290 non-null   int64  \n",
      " 8   latitudinal_distance   4290 non-null   float64\n",
      " 9   longitudinal_distance  4290 non-null   float64\n",
      "dtypes: float64(4), int64(3), object(3)\n",
      "memory usage: 335.3+ KB\n"
     ]
    }
   ],
   "source": [
    "fraud_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddca650",
   "metadata": {},
   "source": [
    "Last step is final adjustment for data types. There are several columns that should be `category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b432d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['category','gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0108089f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T23:57:27.361924Z",
     "start_time": "2022-02-16T23:57:27.322923Z"
    }
   },
   "outputs": [],
   "source": [
    "fraud_train[cat_cols] = fraud_train[cat_cols].astype(\"category\")\n",
    "fraud_train['is_fraud'] = fraud_train['is_fraud'].astype(\"category\")\n",
    "fraud_test[cat_cols] = fraud_test[cat_cols].astype(\"category\")\n",
    "fraud_test['is_fraud'] = fraud_test['is_fraud'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df42f8",
   "metadata": {},
   "source": [
    "## Train Test Inisialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13706ec9",
   "metadata": {},
   "source": [
    "The first step in the modeling section is to define predictor variables and target variables in each of the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6a20789",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:24.981709Z",
     "start_time": "2022-02-17T00:13:24.971757Z"
    }
   },
   "outputs": [],
   "source": [
    "X = fraud_train.drop('is_fraud', axis=1)\n",
    "y = fraud_train['is_fraud']\n",
    "\n",
    "X_unseen = fraud_test.drop('is_fraud', axis=1)\n",
    "y_unseen = fraud_test['is_fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe02a58",
   "metadata": {},
   "source": [
    "Perform data splitting into training data and validation data, with the proportion of train data being 80%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "666f35cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:29.399829Z",
     "start_time": "2022-02-17T00:13:29.377890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1037340, 9)\n",
      "(259335, 9)\n",
      "(1037340,)\n",
      "(259335,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f64294b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count    Dtype   \n",
      "---  ------                 --------------    -----   \n",
      " 0   category               1296675 non-null  category\n",
      " 1   amt                    1296675 non-null  float64 \n",
      " 2   gender                 1296675 non-null  category\n",
      " 3   city_pop               1296675 non-null  int64   \n",
      " 4   age                    1296675 non-null  float64 \n",
      " 5   trans_month            1296675 non-null  int64   \n",
      " 6   trans_year             1296675 non-null  int64   \n",
      " 7   latitudinal_distance   1296675 non-null  float64 \n",
      " 8   longitudinal_distance  1296675 non-null  float64 \n",
      "dtypes: category(2), float64(4), int64(3)\n",
      "memory usage: 71.7 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f73c2",
   "metadata": {},
   "source": [
    " Perform one-hot-enconding to categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8029868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:37.284800Z",
     "start_time": "2022-02-17T00:13:37.180802Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>age</th>\n",
       "      <th>trans_month</th>\n",
       "      <th>trans_year</th>\n",
       "      <th>latitudinal_distance</th>\n",
       "      <th>longitudinal_distance</th>\n",
       "      <th>category_food_dining</th>\n",
       "      <th>category_gas_transport</th>\n",
       "      <th>category_grocery_net</th>\n",
       "      <th>...</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>category_kids_pets</th>\n",
       "      <th>category_misc_net</th>\n",
       "      <th>category_misc_pos</th>\n",
       "      <th>category_personal_care</th>\n",
       "      <th>category_shopping_net</th>\n",
       "      <th>category_shopping_pos</th>\n",
       "      <th>category_travel</th>\n",
       "      <th>gender_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1158821</th>\n",
       "      <td>99.77</td>\n",
       "      <td>4005</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181052</th>\n",
       "      <td>132.98</td>\n",
       "      <td>43102</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874052</th>\n",
       "      <td>9.03</td>\n",
       "      <td>1461</td>\n",
       "      <td>84.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839608</th>\n",
       "      <td>1.29</td>\n",
       "      <td>1423</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162492</th>\n",
       "      <td>6.15</td>\n",
       "      <td>3224</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            amt  city_pop   age  trans_month  trans_year  \\\n",
       "1158821   99.77      4005  75.0            4        2020   \n",
       "181052   132.98     43102  68.0            4        2019   \n",
       "874052     9.03      1461  84.0           12        2019   \n",
       "839608     1.29      1423  21.0           12        2019   \n",
       "1162492    6.15      3224  22.0            4        2020   \n",
       "\n",
       "         latitudinal_distance  longitudinal_distance  category_food_dining  \\\n",
       "1158821                 0.950                  0.804                   0.0   \n",
       "181052                  0.775                  0.571                   0.0   \n",
       "874052                  0.599                  0.016                   0.0   \n",
       "839608                  0.786                  0.560                   0.0   \n",
       "1162492                 0.178                  0.538                   0.0   \n",
       "\n",
       "         category_gas_transport  category_grocery_net  ...  \\\n",
       "1158821                     1.0                   0.0  ...   \n",
       "181052                      0.0                   0.0  ...   \n",
       "874052                      0.0                   0.0  ...   \n",
       "839608                      0.0                   0.0  ...   \n",
       "1162492                     0.0                   0.0  ...   \n",
       "\n",
       "         category_health_fitness  category_home  category_kids_pets  \\\n",
       "1158821                      0.0            0.0                 0.0   \n",
       "181052                       1.0            0.0                 0.0   \n",
       "874052                       0.0            0.0                 0.0   \n",
       "839608                       0.0            0.0                 0.0   \n",
       "1162492                      0.0            0.0                 0.0   \n",
       "\n",
       "         category_misc_net  category_misc_pos  category_personal_care  \\\n",
       "1158821                0.0                0.0                     0.0   \n",
       "181052                 0.0                0.0                     0.0   \n",
       "874052                 0.0                0.0                     0.0   \n",
       "839608                 0.0                0.0                     0.0   \n",
       "1162492                0.0                0.0                     0.0   \n",
       "\n",
       "         category_shopping_net  category_shopping_pos  category_travel  \\\n",
       "1158821                    0.0                    0.0              0.0   \n",
       "181052                     0.0                    0.0              0.0   \n",
       "874052                     0.0                    1.0              0.0   \n",
       "839608                     1.0                    0.0              0.0   \n",
       "1162492                    0.0                    1.0              0.0   \n",
       "\n",
       "         gender_M  \n",
       "1158821       1.0  \n",
       "181052        1.0  \n",
       "874052        1.0  \n",
       "839608        0.0  \n",
       "1162492       1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoder.fit(X_train[cat_cols])\n",
    "\n",
    "X_train_encoded = pd.DataFrame(encoder.transform(X_train[cat_cols]),\n",
    "                               index=X_train.index,\n",
    "                               columns=encoder.get_feature_names(X_train[cat_cols].columns))\n",
    "X_train_dummy = pd.concat([X_train.select_dtypes(exclude='category'),\n",
    "                           X_train_encoded], axis=1)\n",
    "X_train_dummy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca2d777b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:39.999959Z",
     "start_time": "2022-02-17T00:13:39.971036Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(259335, 21)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_encoded = pd.DataFrame(encoder.transform(X_test[cat_cols]),\n",
    "                               index=X_test.index,\n",
    "                               columns=encoder.get_feature_names(X_test[cat_cols].columns))\n",
    "X_test_dummy = pd.concat([X_test.select_dtypes(exclude='category'),\n",
    "                           X_test_encoded], axis=1)\n",
    "X_test_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d1952e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:15:43.292149Z",
     "start_time": "2022-02-17T00:15:43.265228Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4290, 21)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unseen_encoded = pd.DataFrame(encoder.transform(X_unseen[cat_cols]),\n",
    "                               index=X_unseen.index,\n",
    "                               columns=encoder.get_feature_names(X_unseen[cat_cols].columns))\n",
    "X_unseen_dummy = pd.concat([X_unseen.select_dtypes(exclude='category'),\n",
    "                           X_unseen_encoded], axis=1)\n",
    "X_unseen_dummy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ec0a0c",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ae3f9",
   "metadata": {},
   "source": [
    "The first model that is tried to be applied to perform classification and prediction is Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "920630e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:42.532834Z",
     "start_time": "2022-02-17T00:13:42.497994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=2, random_state=100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_fraud = DecisionTreeClassifier(criterion='entropy', max_depth=2, random_state=100)\n",
    "dt_fraud.fit(X_train_dummy, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "364e2ae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:43.870348Z",
     "start_time": "2022-02-17T00:13:43.854393Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_dt = dt_fraud.predict(X_test_dummy)\n",
    "y_pred_prob_dt = dt_fraud.predict_proba(X_test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddc6b5f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:45.344252Z",
     "start_time": "2022-02-17T00:13:45.322312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995473036805676"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_fraud.score(X_train_dummy, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c25e269a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:47.458559Z",
     "start_time": "2022-02-17T00:13:47.443895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9955771492471128"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_fraud.score(X_test_dummy, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b665cb33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:48.896770Z",
     "start_time": "2022-02-17T00:13:48.861447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.2307819748177601\n",
      "Presicion : 0.9633471645919779\n",
      "Accuracy : 0.995473036805676\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "y_pred_train = dt_fraud.predict(X_train_dummy)\n",
    "print(\"Recall :\" , recall_score(y_true=y_train, y_pred=y_pred_train, pos_label='Yes'))\n",
    "print(\"Presicion :\" ,precision_score(y_true=y_train, y_pred=y_pred_train, pos_label='Yes'))\n",
    "print(\"Accuracy :\",accuracy_score(y_true=y_train, y_pred=y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1835f6ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:50.909262Z",
     "start_time": "2022-02-17T00:13:50.881305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.22789115646258504\n",
      "Presicion : 0.9654178674351584\n",
      "Accuracy : 0.9955771492471128\n"
     ]
    }
   ],
   "source": [
    "# test performance\n",
    "y_pred_test = dt_fraud.predict(X_test_dummy)\n",
    "print(\"Recall :\" , recall_score(y_true=y_test, y_pred=y_pred_test, pos_label='Yes'))\n",
    "print(\"Presicion :\" , precision_score(y_true=y_test, y_pred=y_pred_test, pos_label='Yes'))\n",
    "print(\"Accuracy :\", accuracy_score(y_true=y_test, y_pred=y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e93050",
   "metadata": {},
   "source": [
    "The model performance shows that precision and accuracy are very good, reaching 96% and 99%, respectively. Meanwhile, recall is still very low at 22%. Recall becomes a very important metric in this case because we don't want Fraud transaction to be detected as Not Fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38663423",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e2d12c",
   "metadata": {},
   "source": [
    "The next model that is used as a solution for classification is Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0486fea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:14:02.532575Z",
     "start_time": "2022-02-17T00:13:59.656835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_fraud = RandomForestClassifier(random_state=100, oob_score=True)\n",
    "rf_fraud.fit(X_train_dummy, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a8c70fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:14:03.159118Z",
     "start_time": "2022-02-17T00:14:02.537557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.9998343273691186\n",
      "Presicion : 1.0\n",
      "Accuracy : 0.9999990359959127\n"
     ]
    }
   ],
   "source": [
    "# training performance\n",
    "y_pred_rf_train = rf_fraud.predict(X_train_dummy)\n",
    "\n",
    "print(\"Recall :\" , recall_score(y_true=y_train, y_pred=y_pred_rf_train, pos_label='Yes'))\n",
    "print(\"Presicion :\" ,precision_score(y_true=y_train, y_pred=y_pred_rf_train, pos_label='Yes'))\n",
    "print(\"Accuracy :\",accuracy_score(y_true=y_train, y_pred=y_pred_rf_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f6e02cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:14:03.595929Z",
     "start_time": "2022-02-17T00:14:03.452271Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.6591836734693878\n",
      "Presicion : 0.8367875647668394\n",
      "Accuracy : 0.9973393487188386\n"
     ]
    }
   ],
   "source": [
    "# test performance\n",
    "\n",
    "y_pred_rf_test = rf_fraud.predict(X_test_dummy)\n",
    "\n",
    "print(\"Recall :\" , recall_score(y_true=y_test, y_pred=y_pred_rf_test, pos_label='Yes'))\n",
    "print(\"Presicion :\" , precision_score(y_true=y_test, y_pred=y_pred_rf_test, pos_label='Yes'))\n",
    "print(\"Accuracy :\", accuracy_score(y_true=y_test, y_pred=y_pred_rf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788dc5a",
   "metadata": {},
   "source": [
    "The results of the Random Forest model show that recall, precision, and accuracy have excelled in train data. The recall value on the test data is also better than the Decision Tree. However, this value is still considered to need to be improved again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705b99de",
   "metadata": {},
   "source": [
    "## Improve Model with Balanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f077ecf",
   "metadata": {},
   "source": [
    "Inspect proportion of each value of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2f18236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:13:35.261617Z",
     "start_time": "2022-02-17T00:13:35.249649Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     0.994181\n",
       "Yes    0.005819\n",
       "Name: is_fraud, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d0f5c",
   "metadata": {},
   "source": [
    "The result shows there is imbalance data, which is 99% of the data set is Not Fraud. So by using a randomoversampler, the target value is equalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9665759d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:14:07.560437Z",
     "start_time": "2022-02-17T00:14:07.508221Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     1031304\n",
       "Yes    1031304\n",
       "Name: is_fraud, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=100)\n",
    "X_train_up, y_train_up = oversampler.fit_resample(X_train_dummy, y_train)\n",
    "y_train_up.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9573e18",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee974b7d",
   "metadata": {},
   "source": [
    "Decision Tree performs with balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61e2704b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:14:09.537923Z",
     "start_time": "2022-02-17T00:14:09.436302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=7, random_state=100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_fraud_up = DecisionTreeClassifier(criterion='entropy', max_depth=7, random_state=100)\n",
    "dt_fraud_up.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "426be0e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:14:10.838380Z",
     "start_time": "2022-02-17T00:14:10.793810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.960697330757953\n",
      "Presicion : 0.9359531594067085\n",
      "Accuracy : 0.9474786289978513\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_up = dt_fraud_up.predict(X_train_up)\n",
    "print(\"Recall :\" , recall_score(y_true=y_train_up, y_pred=y_pred_train_up, pos_label='Yes'))\n",
    "print(\"Presicion :\" ,precision_score(y_true=y_train_up, y_pred=y_pred_train_up, pos_label='Yes'))\n",
    "print(\"Accuracy :\",accuracy_score(y_true=y_train_up, y_pred=y_pred_train_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dce4ac32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:16:36.963938Z",
     "start_time": "2022-02-17T00:16:36.939005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.9505827505827505\n",
      "Presicion : 0.9374712643678161\n",
      "Accuracy : 0.9435897435897436\n"
     ]
    }
   ],
   "source": [
    "y_pred_dt_test_up_unseen = dt_fraud_up.predict(X_unseen_dummy)\n",
    "\n",
    "print(\"Recall :\" , recall_score(y_true=y_unseen, y_pred=y_pred_dt_test_up_unseen, pos_label='Yes'))\n",
    "print(\"Presicion :\" , precision_score(y_true=y_unseen, y_pred=y_pred_dt_test_up_unseen, pos_label='Yes'))\n",
    "print(\"Accuracy :\", accuracy_score(y_true=y_unseen, y_pred=y_pred_dt_test_up_unseen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ad662",
   "metadata": {},
   "source": [
    "The result of Desicision Tree with balanced data performs better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ac5eb",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a562c00",
   "metadata": {},
   "source": [
    "Random Forest performs with balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b09986da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:03:33.120134Z",
     "start_time": "2022-02-17T00:03:27.728734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_fraud_up = RandomForestClassifier(random_state=100, oob_score=True)\n",
    "rf_fraud_up.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "798d9113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:03:34.311523Z",
     "start_time": "2022-02-17T00:03:33.130110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 1.0\n",
      "Presicion : 1.0\n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_up_rf = rf_fraud_up.predict(X_train_up)\n",
    "print(\"Recall :\" , recall_score(y_true=y_train_up, y_pred=y_pred_train_up_rf, pos_label='Yes'))\n",
    "print(\"Presicion :\" ,precision_score(y_true=y_train_up, y_pred=y_pred_train_up_rf, pos_label='Yes'))\n",
    "print(\"Accuracy :\",accuracy_score(y_true=y_train_up, y_pred=y_pred_train_up_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84a37a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:03:35.957237Z",
     "start_time": "2022-02-17T00:03:35.873888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.719047619047619\n",
      "Presicion : 0.8181114551083591\n",
      "Accuracy : 0.997501301405518\n"
     ]
    }
   ],
   "source": [
    "# test performance\n",
    "\n",
    "y_pred_rf_test_up = rf_fraud_up.predict(X_test_dummy)\n",
    "\n",
    "print(\"Recall :\" , recall_score(y_true=y_test, y_pred=y_pred_rf_test_up, pos_label='Yes'))\n",
    "print(\"Presicion :\" , precision_score(y_true=y_test, y_pred=y_pred_rf_test_up, pos_label='Yes'))\n",
    "print(\"Accuracy :\", accuracy_score(y_true=y_test, y_pred=y_pred_rf_test_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3b9487",
   "metadata": {},
   "source": [
    "Inline with result of Decision Tree, Random Forest shows better with balanced data. The model is working perfectly on the data train. But, on the data test, Desicion Tree performs better than Random Forest. Recall as the preferred metric in this case in Random Forest only reaches 72.85%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc418fd2",
   "metadata": {},
   "source": [
    "## Random Forest with Best Parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0481b5",
   "metadata": {},
   "source": [
    "Then to optimize and improve the model, the best parameter search is carried out using the Random Search Cross Validation technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37fbe447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3] END criterion=entropy, max_depth=24, max_features=sqrt, min_samples_leaf=12, min_samples_split=32;, score=0.997 total time= 8.3min\n",
      "[CV 2/3] END criterion=entropy, max_depth=24, max_features=sqrt, min_samples_leaf=12, min_samples_split=32;, score=0.997 total time= 7.9min\n",
      "[CV 3/3] END criterion=entropy, max_depth=24, max_features=sqrt, min_samples_leaf=12, min_samples_split=32;, score=0.997 total time= 7.6min\n",
      "[CV 1/3] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=30, min_samples_split=47;, score=0.996 total time= 6.8min\n",
      "[CV 2/3] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=30, min_samples_split=47;, score=0.996 total time= 7.3min\n",
      "[CV 3/3] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=30, min_samples_split=47;, score=0.996 total time= 6.8min\n",
      "[CV 1/3] END criterion=gini, max_depth=16, max_features=sqrt, min_samples_leaf=9, min_samples_split=48;, score=0.993 total time= 7.1min\n",
      "[CV 2/3] END criterion=gini, max_depth=16, max_features=sqrt, min_samples_leaf=9, min_samples_split=48;, score=0.993 total time= 7.5min\n",
      "[CV 3/3] END criterion=gini, max_depth=16, max_features=sqrt, min_samples_leaf=9, min_samples_split=48;, score=0.993 total time= 7.4min\n",
      "[CV 1/3] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=35, min_samples_split=20;, score=0.976 total time= 6.8min\n",
      "[CV 2/3] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=35, min_samples_split=20;, score=0.977 total time= 6.8min\n",
      "[CV 3/3] END criterion=gini, max_depth=13, max_features=log2, min_samples_leaf=35, min_samples_split=20;, score=0.977 total time= 6.8min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(oob_score=True,\n",
       "                                                    random_state=123),\n",
       "                   n_iter=4,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': range(10, 50),\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': range(2, 50),\n",
       "                                        'min_samples_split': range(2, 50)},\n",
       "                   random_state=123, verbose=3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# hyperparameter distributions\n",
    "param_random_rf = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth': range(10, 50),\n",
    "    'min_samples_split': range(2, 50),\n",
    "    'min_samples_leaf': range(2, 50),\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=123, oob_score=True)\n",
    "\n",
    "model_rf_random_up = RandomizedSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_distributions=param_random_rf,\n",
    "    n_iter=4,\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    random_state=123)\n",
    "\n",
    "model_rf_random_up.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "129c1888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.8321678321678322\n",
      "Presicion : 0.9988808058198098\n",
      "Accuracy : 0.9156177156177157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "y_pred_rf_test_up_unseen = model_rf_random_up.predict(X_unseen_dummy)\n",
    "\n",
    "print(\"Recall :\" , recall_score(y_true=y_unseen, y_pred=y_pred_rf_test_up_unseen, pos_label='Yes'))\n",
    "print(\"Presicion :\" , precision_score(y_true=y_unseen, y_pred=y_pred_rf_test_up_unseen, pos_label='Yes'))\n",
    "print(\"Accuracy :\", accuracy_score(y_true=y_unseen, y_pred=y_pred_rf_test_up_unseen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa8a33",
   "metadata": {},
   "source": [
    "The results obtained are considered quite good, but we need hight recall value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2031fb2",
   "metadata": {},
   "source": [
    "## Desicion Tree with Best Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e3ae07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1356, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['No', 'Yes']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END max_depth=49, max_features=sqrt, min_samples_leaf=29, min_samples_split=22;, score=nan total time=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1356, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['No', 'Yes']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END max_depth=49, max_features=sqrt, min_samples_leaf=29, min_samples_split=22;, score=nan total time=  13.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1356, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['No', 'Yes']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END max_depth=49, max_features=sqrt, min_samples_leaf=29, min_samples_split=22;, score=nan total time=  13.8s\n",
      "[CV 1/3] END max_depth=79, max_features=25, min_samples_leaf=39, min_samples_split=45;, score=nan total time=   3.8s\n",
      "[CV 2/3] END max_depth=79, max_features=25, min_samples_leaf=39, min_samples_split=45;, score=nan total time=   3.5s\n",
      "[CV 3/3] END max_depth=79, max_features=25, min_samples_leaf=39, min_samples_split=45;, score=nan total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1356, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['No', 'Yes']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END max_depth=43, max_features=sqrt, min_samples_leaf=65, min_samples_split=6;, score=nan total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1356, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['No', 'Yes']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END max_depth=43, max_features=sqrt, min_samples_leaf=65, min_samples_split=6;, score=nan total time=  14.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1356, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['No', 'Yes']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END max_depth=43, max_features=sqrt, min_samples_leaf=65, min_samples_split=6;, score=nan total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1356, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['No', 'Yes']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END max_depth=19, max_features=None, min_samples_leaf=23, min_samples_split=80;, score=nan total time=  25.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1356, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['No', 'Yes']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END max_depth=19, max_features=None, min_samples_leaf=23, min_samples_split=80;, score=nan total time=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1356, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['No', 'Yes']\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "3 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END max_depth=19, max_features=None, min_samples_leaf=23, min_samples_split=80;, score=nan total time=  31.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=123),\n",
       "                   n_iter=4,\n",
       "                   param_distributions={'max_depth': range(10, 100),\n",
       "                                        'max_features': [20, 21, 22, 23, 24, 25,\n",
       "                                                         26, 27, 28, 29, 'sqrt',\n",
       "                                                         'log2', None],\n",
       "                                        'min_samples_leaf': range(2, 100),\n",
       "                                        'min_samples_split': range(2, 100)},\n",
       "                   random_state=123, scoring='recall', verbose=3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter distributions\n",
    "param_random_dt = {\n",
    "    'max_depth': range(10, 100),\n",
    "    'min_samples_split': range(2, 100),\n",
    "    'min_samples_leaf': range(2, 100),\n",
    "    'max_features': list(range(20, 30)) + ['sqrt', 'log2', None]\n",
    "    }\n",
    "\n",
    "model_dt_random_up = RandomizedSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=123),\n",
    "    param_distributions=param_random_dt,\n",
    "    n_iter=4,\n",
    "    scoring='recall',\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    random_state=123)\n",
    "\n",
    "model_dt_random_up.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87333753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall : 0.8522144522144522\n",
      "Presicion : 0.9827956989247312\n",
      "Accuracy : 0.9186480186480186\n"
     ]
    }
   ],
   "source": [
    "y_pred_dt_test_up_unseen = model_dt_random_up.predict(X_unseen_dummy)\n",
    "\n",
    "print(\"Recall :\" , recall_score(y_true=y_unseen, y_pred=y_pred_dt_test_up_unseen, pos_label='Yes'))\n",
    "print(\"Presicion :\" , precision_score(y_true=y_unseen, y_pred=y_pred_dt_test_up_unseen, pos_label='Yes'))\n",
    "print(\"Accuracy :\", accuracy_score(y_true=y_unseen, y_pred=y_pred_dt_test_up_unseen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1fb8c",
   "metadata": {},
   "source": [
    "Decision Tree with best parameters improve on Precision. However, because in this case we want to anticipate transactions that are declared not fraudulent even though they are fraudulent. Then the metric that is considered is recall. So that by comparing the evaluation values, especially recall, the decision tree with balanced data came out as the best classifier. Furthermore, this best model is stored under the name `dt_fraud_up`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "418f1566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dt_fraud_up']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(dt_fraud_up,'dt_fraud_up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d812b02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_rf_random_up']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_rf_random_up,'model_rf_random_up')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algoritma-pln",
   "language": "python",
   "name": "algoritma-pln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
